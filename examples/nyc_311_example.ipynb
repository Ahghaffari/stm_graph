{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293b07ca",
   "metadata": {},
   "source": [
    "# NYC 311 Service Request Prediction with STM-Graph\n",
    "\n",
    "This notebook demonstrates how to use the STM-Graph library to analyze New York City 311 service request data and do prediction. We'll go through the complete workflow:\n",
    "\n",
    "1. Loading and preprocessing the raw data\n",
    "2. Creating spatial mappings using Degree-based Voronoi partitioning\n",
    "3. Extracting OpenStreetMap features / Urban Features Graph Creation\n",
    "4. Building a graph representation of the data\n",
    "5. Creating temporal graph dataset\n",
    "6. Visualizing spatial and temporal patterns\n",
    "7. Training a GNN model for service request prediction\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a764c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_graph_path = \"/home/ubuntu/STM-Graph/src\"\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append(stm_graph_path)\n",
    "import stm_graph\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "# Define the data and output directories\n",
    "DATA_DIR = \"/mnt/data/nyc_crash_311\"\n",
    "DATASET = \"311_Service_Requests_from_2010_to_Present_20241218.csv\"\n",
    "OUTPUT_DIR = \"/mnt/data/nyc_crash_311/stm_graph/nyc/311\"\n",
    "\n",
    "# Define geographic boundaries for NYC\n",
    "NYC_BOUNDS = {\n",
    "    \"min_lat\": 40.4774,  # Southern boundary\n",
    "    \"max_lat\": 40.9176,  # Northern boundary\n",
    "    \"min_lon\": -74.2591,  # Western boundary\n",
    "    \"max_lon\": -73.7004,  # Eastern boundary\n",
    "}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5d773",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "First, we'll load the NYC 311 service request data and preprocess it using STM-Graph's built-in functions. This dataset contains citizen reports of non-emergency issues like noise complaints, illegal parking, etc.\n",
    "\n",
    "The preprocessing steps include:\n",
    "- Filtering data within NYC boundaries\n",
    "- Converting coordinates to a proper spatial format\n",
    "- Standardizing column names\n",
    "- Filtering to a specific time range for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process with STM-Graph\n",
    "print(f\"Processing 311 data from {os.path.join(DATA_DIR, DATASET)}\")\n",
    "gdf_311 = stm_graph.preprocess_dataset(\n",
    "    data_path=DATA_DIR,\n",
    "    dataset=DATASET,\n",
    "    time_col=\"created_time\",\n",
    "    lat_col=\"Latitude\",\n",
    "    lng_col=\"Longitude\",\n",
    "    column_mapping={\n",
    "        \"Unique Key\": \"unique_key\",\n",
    "        \"Created Date\": \"created_time\",\n",
    "        \"Closed Date\": \"closed_time\",\n",
    "        \"Agency\": \"agency\",\n",
    "        \"Complaint Type\": \"complaint_type\",\n",
    "        \"Descriptor\": \"descriptor\",\n",
    "        \"Latitude\": \"latitude\",\n",
    "        \"Longitude\": \"longitude\",\n",
    "        \"Location\": \"location\",\n",
    "    },\n",
    "    filter_dates=(\"2017-06-01 00:00:00\", \"2018-06-30 23:59:59\"),\n",
    "    testing_mode=True,\n",
    "    test_bounds=NYC_BOUNDS,\n",
    "    visualize=True,\n",
    "    fig_format=\"png\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    show_background_map=True,\n",
    "    point_color=\"blue\",\n",
    "    point_alpha=0.5,\n",
    "    point_size=1\n",
    ")\n",
    "\n",
    "print(f\"Processed dataset shape: {gdf_311.shape}\")\n",
    "print(f\"Time range: {gdf_311['created_time'].min()} to {gdf_311['created_time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71259303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the distribution of 311 complaint types\n",
    "complaint_counts = gdf_311['complaint_type'].value_counts()\n",
    "print(\"Top 10 complaint types:\")\n",
    "print(complaint_counts.head(10))\n",
    "\n",
    "# Visualize the top complaint types\n",
    "plt.figure(figsize=(12, 6))\n",
    "complaint_counts.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 311 Complaint Types')\n",
    "plt.ylabel('Number of Reports')\n",
    "plt.xlabel('Complaint Type')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be2c98",
   "metadata": {},
   "source": [
    "## 2. Spatial Mapping\n",
    "\n",
    "Next, we'll apply a spatial mapping to divide NYC into regions. For this dataset, we'll use a Degree-based Voronoi partitioning approach, which creates regions of varying sizes based on the important road network junctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Degree-based Voronoi mapping to the data\n",
    "mapper = stm_graph.VoronoiDegreeMapping(\n",
    "    small_cell_size=5000,\n",
    "    large_cell_size=20000,\n",
    "    meter_crs=\"EPSG:32618\",\n",
    ")\n",
    "\n",
    "# Apply the mapping to get district geometries and point-to-partition mapping\n",
    "district_gdf, point_to_partition = mapper.create_mapping(gdf_311)\n",
    "\n",
    "print(f\"Created mapping with {len(district_gdf)} regions\")\n",
    "print(f\"Points with valid mapping: {(point_to_partition >= 0).sum()} of {len(point_to_partition)}\")\n",
    "\n",
    "# Visualize the mapping\n",
    "mapper.visualize(\n",
    "    points_gdf=gdf_311,\n",
    "    partition_gdf=district_gdf,\n",
    "    point_to_partition=point_to_partition,\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    remove_empty=True,\n",
    "    testing_mode=False,\n",
    "    file_format=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c727b4",
   "metadata": {},
   "source": [
    "## 3. OSM Feature Extraction / Urban Features Graph Creation\n",
    "\n",
    "Now we'll extract features from OpenStreetMap (OSM) to enrich our model with contextual information about each area. These features provide important context about the urban environment that may influence service request patterns.\n",
    "\n",
    "For example:\n",
    "- More restaurants might correlate with more noise complaints\n",
    "- Areas with more roads might have more pothole reports\n",
    "- Areas with more parks might have different patterns of maintenance requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature types to extract\n",
    "feature_types = ['poi', 'road', 'junction']\n",
    "\n",
    "# Extract OSM features\n",
    "osm_cache_dir = os.path.join(OUTPUT_DIR, \"osm_cache\")\n",
    "osm_features = stm_graph.extract_osm_features(\n",
    "    regions_gdf=district_gdf,\n",
    "    bounds=NYC_BOUNDS,\n",
    "    cache_dir=osm_cache_dir,\n",
    "    feature_types=feature_types,\n",
    "    normalize=True,\n",
    "    meter_crs=\"EPSG:32618\",\n",
    "    lat_lon_crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Print available features\n",
    "print(f\"Extracted {len(osm_features.columns)} OSM features\")\n",
    "print(\"\\nFeature sample:\")\n",
    "osm_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7746080",
   "metadata": {},
   "source": [
    "## 4. Graph Construction\n",
    "\n",
    "Now we'll build a graph representation of our data. In this graph:\n",
    "- Nodes represent Voronoi regions\n",
    "- Edges represent adjacency relationships between regions\n",
    "- Node features include OSM features and service request statistics\n",
    "\n",
    "This graph structure allows us to use Graph Neural Networks (GNNs) to model the spatial relationships between different areas of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points that have valid mappings\n",
    "gdf_311_valid = gdf_311[point_to_partition >= 0].copy()\n",
    "point_to_partition_valid = point_to_partition[point_to_partition >= 0].copy()\n",
    "\n",
    "print(f\"Using {len(gdf_311_valid)} valid points for graph construction\")\n",
    "\n",
    "# Build graph with static features\n",
    "graph_data = stm_graph.build_graph_and_augment(\n",
    "    grid_gdf=district_gdf,\n",
    "    points_gdf=gdf_311_valid,\n",
    "    point_to_cell=point_to_partition_valid,\n",
    "    adj_matrix=mapper.get_adjacency_matrix(),\n",
    "    road_edges_gdf=mapper.get_road_network(),\n",
    "    adjacency_type=\"road_based\",\n",
    "    remove_empty_nodes=True,\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    save_flag=True,\n",
    "    static_features=osm_features,\n",
    "    meter_crs=\"EPSG:32618\",\n",
    "    \n",
    ")\n",
    "\n",
    "# Extract graph components\n",
    "edge_index = graph_data[\"edge_index\"]\n",
    "edge_weight = graph_data[\"edge_weight\"]\n",
    "node_features = graph_data[\"node_features\"]\n",
    "augmented_df = graph_data[\"augmented_df\"]\n",
    "node_ids = graph_data[\"node_ids\"]\n",
    "\n",
    "print(f\"Built graph with {edge_index.shape[1]} edges and {graph_data['num_nodes']} nodes\")\n",
    "print(f\"Node features shape: {node_features.shape}\")\n",
    "\n",
    "# Display augmented dataframe\n",
    "augmented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591576c",
   "metadata": {},
   "source": [
    "## 5. Temporal Dataset Creation\n",
    "\n",
    "With our graph structure in place, we'll now create a temporal dataset for time-aware analysis and prediction. We'll:\n",
    "\n",
    "1. Bin service requests into daily intervals\n",
    "2. Create sliding windows of data for training\n",
    "3. Add time-based features (day of week, hour of day)\n",
    "4. Normalize the features for better model training\n",
    "\n",
    "This temporal dataset will allow us to capture patterns in when and where 311 requests occur throughout NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal dataset\n",
    "temporal_dataset, dataset_path, metadata = stm_graph.create_temporal_dataset(\n",
    "    edge_index=edge_index,\n",
    "    augmented_df=augmented_df,\n",
    "    edge_weights=edge_weight,\n",
    "    node_ids=node_ids,\n",
    "    static_features=osm_features,\n",
    "    time_col=\"created_time\",\n",
    "    cell_col=\"cell_id\",\n",
    "    bin_type=\"daily\",\n",
    "    interval_hours=1,\n",
    "    history_window=3,\n",
    "    use_time_features=False,\n",
    "    task=\"classification\",\n",
    "    horizon=1,\n",
    "    downsample_factor=1,\n",
    "    normalize=True,\n",
    "    scaler_type=\"minmax\",\n",
    "    dataset_name=\"nyc_311_dataset\",\n",
    "    output_format=\"4d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f558bc",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "Now let's create visualizations to better understand our 311 data patterns. We'll create:\n",
    "\n",
    "1. Time series plots showing service request trends over time\n",
    "2. Spatial network visualizations showing request density across NYC\n",
    "3. Temporal heatmaps showing patterns across time\n",
    "\n",
    "These visualizations help reveal when and where different types of service requests occur, which can inform city resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_dataset_3d = stm_graph.convert_4d_to_3d_dataset(\n",
    "    temporal_dataset, static_features_count=osm_features.shape[1])\n",
    "\n",
    "# Plot time series for the most active nodes\n",
    "stm_graph.plot_node_time_series(\n",
    "    temporal_dataset_3d,\n",
    "    num_nodes=5,  # Show 5 nodes\n",
    "    selection_method=\"highest_activity\",  # Select most active nodes\n",
    "    feature_idx=0,  # Event count feature\n",
    "    plot_type=\"2d\",  # 2D line plot\n",
    "    start_time=\"2017-04-01\",  # Start date for x-axis\n",
    "    time_delta=timedelta(hours=1),  # Hourly data\n",
    "    title=\"311 Service Requests Over Time (Most Active Nodes)\",\n",
    "    figsize=(15, 8),\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    filename=\"311_time_series_top\",\n",
    "    file_format=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3D visualization for most active nodes\n",
    "stm_graph.plot_node_time_series(\n",
    "    temporal_dataset_3d,\n",
    "    num_nodes=3,  # Show 3 nodes\n",
    "    selection_method=\"highest_activity\",  # Select most active nodes\n",
    "    feature_idx=0,  # Event count feature\n",
    "    plot_type=\"3d\",  # 3D surface plot\n",
    "    n_steps=168,  # First week (7 days * 24 hours)\n",
    "    title=\"311 Service Requests 3D Visualization Over Time\",\n",
    "    figsize=(15, 10),\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    filename=\"311_time_series_3d\",\n",
    "    file_format=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract service request counts for each region (node) at a specific time\n",
    "time_step = 24  # Example: events after 24 hours\n",
    "node_counts = np.array(\n",
    "    [\n",
    "        temporal_dataset_3d.features[time_step][node, 0].item()\n",
    "        for node in range(graph_data[\"num_nodes\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot spatial network with region and edge colors\n",
    "stm_graph.plot_spatial_network(\n",
    "    regions_gdf=district_gdf,\n",
    "    edge_index=edge_index,\n",
    "    edge_weights=edge_weight,\n",
    "    node_values=node_counts,\n",
    "    node_ids=node_ids,\n",
    "    time_step=time_step,\n",
    "    title=\"Service Request Density After 24 Hours\",\n",
    "    node_cmap=\"YlOrRd\",  # Red-yellow colormap for heat\n",
    "    edge_cmap=\"viridis\",  # Blue-green for edges\n",
    "    map_style=ctx.providers.CartoDB.Positron,\n",
    "    figsize=(15, 15),\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    filename=\"311_spatial_network\",\n",
    "    file_format=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ef02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporal heatmap to see patterns across time and nodes\n",
    "stm_graph.plot_temporal_heatmap(\n",
    "    temporal_dataset_3d,\n",
    "    num_nodes=10,\n",
    "    feature_idx=0,  # Event count feature\n",
    "    selection_method=\"highest_activity\",\n",
    "    time_delta=timedelta(hours=1),\n",
    "    n_steps=168,  # First week\n",
    "    title=\"311 Requests Temporal Heatmap (First Week)\",\n",
    "    figsize=(15, 8),\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    filename=\"temporal_heatmap\",\n",
    "    file_format=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c622d6fc",
   "metadata": {},
   "source": [
    "## 7. Weekly and Daily Patterns Analysis\n",
    "\n",
    "Let's analyze the weekly and daily patterns in the 311 service request data to identify when different types of requests are most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856db20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the created_time to datetime if not already\n",
    "gdf_311_valid['created_time'] = pd.to_datetime(gdf_311_valid['created_time'])\n",
    "\n",
    "# Extract day of week and hour\n",
    "gdf_311_valid['day_of_week'] = gdf_311_valid['created_time'].dt.day_name()\n",
    "gdf_311_valid['hour_of_day'] = gdf_311_valid['created_time'].dt.hour\n",
    "\n",
    "# Plot requests by day of week\n",
    "plt.figure(figsize=(12, 6))\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_counts = gdf_311_valid['day_of_week'].value_counts().reindex(day_order)\n",
    "day_counts.plot(kind='bar')\n",
    "plt.title('311 Service Requests by Day of Week')\n",
    "plt.ylabel('Number of Requests')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot requests by hour of day\n",
    "plt.figure(figsize=(12, 6))\n",
    "hour_counts = gdf_311_valid['hour_of_day'].value_counts().sort_index()\n",
    "hour_counts.plot(kind='bar')\n",
    "plt.title('311 Service Requests by Hour of Day')\n",
    "plt.xlabel('Hour (24-hour format)')\n",
    "plt.ylabel('Number of Requests')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2335e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top complaint types by day of week\n",
    "plt.figure(figsize=(14, 8))\n",
    "top_complaints = gdf_311_valid['complaint_type'].value_counts().head(5).index\n",
    "day_complaint_counts = pd.crosstab(gdf_311_valid['day_of_week'], gdf_311_valid['complaint_type'])\n",
    "day_complaint_counts = day_complaint_counts[top_complaints].reindex(day_order)\n",
    "day_complaint_counts.plot(kind='bar', stacked=True)\n",
    "plt.title('Top 5 Complaint Types by Day of Week')\n",
    "plt.ylabel('Number of Requests')\n",
    "plt.legend(title='Complaint Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322f601",
   "metadata": {},
   "source": [
    "## 8. Model Training\n",
    "\n",
    "Finally, we'll train a Graph Neural Network (GNN) model to predict service request events. We'll use the ST-GCN model, which is designed specifically for spatio-temporal graph data. We can use other models as well; sample codes provided.\n",
    "\n",
    "This model will predict whether service requests will occur in each area in the next time step. Different designed custom models can be used or any supported model from Torch Geometric Temporal can be used. More custom models can be added. Training logs will be saved in logs folder locally in output directory. [Weights & Biases](https://wandb.ai/) integration is done and you can login and use online dashboard to control the training process and track training metrics and process live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STGCN\n",
    "model = stm_graph.create_model(\n",
    "    model_name=\"stgcn\",\n",
    "    source=\"custom\",\n",
    "    num_nodes=temporal_dataset.features[0].shape[0],\n",
    "    in_channels=temporal_dataset.features[0].shape[2],\n",
    "    out_channels=1,\n",
    "    hidden_dim=64,\n",
    "    k=3,\n",
    "    embedding_dimensions=16,\n",
    "    dropout=0.2,\n",
    "    task=\"classification\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "results = stm_graph.train_model(\n",
    "    model=model,\n",
    "    dataset=temporal_dataset,\n",
    "    optimizer_name=\"adam\",\n",
    "    learning_rate=0.0001,\n",
    "    task=\"classification\",\n",
    "    num_epochs=500,  \n",
    "    batch_size=10,\n",
    "    batch_to_device=True,\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
    "    use_nested_tqdm=True,\n",
    "    early_stopping=True,\n",
    "    patience=50,\n",
    "    scheduler_type=\"step\",\n",
    "    lr_decay_epochs=50,\n",
    "    lr_decay_factor=1,\n",
    "    wandb_project=\"stm_graph_311\",\n",
    "    experiment_name=\"stgcn\",\n",
    "    use_wandb=True, \n",
    "    fixed_batch_size=True,\n",
    "    log_dir=OUTPUT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a42b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GCN\n",
    "model = stm_graph.create_model(\n",
    "    model_name=\"gcn\",\n",
    "    source=\"custom\",\n",
    "    in_channels=temporal_dataset_3d.features[0].shape[1],\n",
    "    out_channels=1,\n",
    "    hidden_channels=64,\n",
    "    dropout=0.2,\n",
    "    task=\"classification\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "results = stm_graph.train_model(\n",
    "    model=model,\n",
    "    dataset=temporal_dataset_3d,\n",
    "    optimizer_name=\"adam\",\n",
    "    learning_rate=0.0001,\n",
    "    task=\"classification\",\n",
    "    num_epochs=500,  \n",
    "    batch_size=10,\n",
    "    batch_to_device=True,\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
    "    use_nested_tqdm=True,\n",
    "    early_stopping=True,\n",
    "    patience=50,\n",
    "    scheduler_type=\"step\",\n",
    "    lr_decay_epochs=50,\n",
    "    lr_decay_factor=1,\n",
    "    wandb_project=\"stm_graph_311\",\n",
    "    experiment_name=\"gcn\",\n",
    "    use_wandb=True, \n",
    "    fixed_batch_size=True,\n",
    "    log_dir=OUTPUT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TGCN\n",
    "model = stm_graph.create_model(\n",
    "    model_name=\"tgcn\",\n",
    "    source=\"custom\",\n",
    "    in_channels=temporal_dataset_3d.features[0].shape[1],\n",
    "    out_channels=1,\n",
    "    batch_size=1,\n",
    "    task=\"classification\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "results = stm_graph.train_model(\n",
    "    model=model,\n",
    "    dataset=temporal_dataset_3d,\n",
    "    optimizer_name=\"adam\",\n",
    "    learning_rate=0.0001,\n",
    "    task=\"classification\",\n",
    "    num_epochs=500,  \n",
    "    batch_size=1,\n",
    "    batch_to_device=True,\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
    "    use_nested_tqdm=True,\n",
    "    early_stopping=True,\n",
    "    patience=50,\n",
    "    scheduler_type=\"step\",\n",
    "    lr_decay_epochs=50,\n",
    "    lr_decay_factor=1,\n",
    "    wandb_project=\"stm_graph_311\",\n",
    "    experiment_name=\"tgcn\",\n",
    "    use_wandb=True, \n",
    "    fixed_batch_size=True,\n",
    "    log_dir=OUTPUT_DIR,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
